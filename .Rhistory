svmfit <- svm(class ~ .,
data = train,
kernel = "linear",
cost = 10,
scale = FALSE); summary(svmfit)
svmfit <- svm(as.factor(Purchase) ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
plot(svmfit, training_set)
plot(svmfit, train)
library(tidyverse)
library(e1071)
set.seed(2345)
# create the data for classification
x <- matrix(rnorm(20*2), ncol=2)
class <- c(rep(-1,10), rep(1,10))
x[class == 1, ] = x[class == 1, ] + 1
# perfectly linearly seperable?
ggplot(data.frame(x), aes(X1, X2, color = factor(class))) +
geom_point() +
theme_minimal()
# encode as factor for classification, rather than regression
train <- data.frame(x = x, class = as.factor(class))
svmfit1 <- svm(class ~ .,
data = train,
kernel = "linear",
cost = 10,
scale = FALSE); summary(svmfit1)
plot(svmfit1, train)
split<- sample.split(as.factor(OJ$Purchase), SplitRatio = 0.7476636)
training_set<- subset(OJ, split==TRUE)
test_set<- subset(OJ, split==FALSE)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
plot(svmfit, training_set)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
dim(OJ)
set.seed(888)
nrow(OJ)
800/1070
split<- sample.split(as.factor(OJ$Purchase), SplitRatio = 0.7476636)
training_set<- subset(OJ, split==TRUE)
test_set<- subset(OJ, split==FALSE)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
svmfit$index
class_1 <- predict(svmfit, testing_set)
class_1 <- predict(svmfit, test_set)
table(predicted = class_1,
true = testing_set$Purchased)
class_1 <- predict(svmfit, test_set)
table(predicted = class_1,
true = test_set$Purchased)
y_pred = predict(svmfit, newdata = test_set[-3])
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ, y=as.factor(OJ$Purchase))
split<- sample.split(OJ$Purchase, SplitRatio = 0.7476636)
training_set<- subset(OJ, split==TRUE)
test_set<- subset(OJ, split==FALSE)
nrow(OJ.data)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
plot(svmfit,training_set)
plot.svm(svmfit,training_set)
y_pred = predict(svmfit, newdata = test_set[-3])
View(test_set)
y_pred = predict(svmfit, newdata = test_set[,-1])
confusion_matrix = table(test_set[, 1], y_pred)
confusion_matrix
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
classification_error <- 1- sum(pred_test == test_set)/length(pred_test)
classification_error <- 1- sum(pred_test == test_set[,1])/length(pred_test)
pred_train<-predict(svmfit,newdata=training_set[,-1])
classification_error <- 1- sum(pred_train == training_set[,-1])/length(pred_train)
pred_train<-predict(svmfit, newdata = training_set[,-1])
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
#Testing Set Error Rate
classification_error_test <- 1- sum(pred_test == test_set[,1])/length(pred_test)
classification_error_test
pred_train<-predict(svmfit, newdata = training_set[,-1])
classification_error_train <- 1- sum(pred_train == training_set[,1])/length(pred_train)
classification_error_train
classification_error_test <- 1- sum(pred_test == test_set[,1])/length(pred_test)
classification_error_test
opt_cost <- tune(svmfit, Product~., data = OJ.data, kernel = "linear",
ranges = list(cost = c(0.01:1000)))
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ, y=as.factor(OJ$Purchase))
nrow(OJ.data)
800/1070
split<- sample.split(OJ.data$Purchase, SplitRatio = 0.7476636)
training_set<- subset(OJ.data, split==TRUE)
test_set<- subset(OJ, split==FALSE)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
pred_test <- predict(svmfit, newdata = test_set[,-1])
pred_test <- predict(svmfit, newdata = test_set[,-1])
pred_test <- predict(svmfit, newdata = test_set[,1])
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ, y=as.factor(OJ$Purchase))
nrow(OJ.data)
800/1070
split<- sample.split(OJ.data$Purchase, SplitRatio = 0.7476636)
training_set<- subset(OJ.data, split==TRUE)
test_set<- subset(OJ.data, split==FALSE)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
classification_error_test <- 1- sum(pred_test == test_set[,1])/length(pred_test)
classification_error_test
pred_train<-predict(svmfit, newdata = training_set[,-1])
classification_error_train <- 1- sum(pred_train == training_set[,1])/length(pred_train)
classification_error_train
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
pred_train<-predict(svmfit, newdata = training_set[,-1])
classification_error_train <- 1- sum(pred_train == training_set[,-1])/length(pred_train)
classification_error_test <- 1- sum(pred_test == test_set[,-1])/length(pred_test)
classification_error_test <- 1- sum(pred_test == test_set[,1])/length(pred_test)
classification_error_test
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ, y=as.factor(OJ$Purchase))
View(OJ.data)
OJ.data=data.frame(OJ, Purchase=as.factor(OJ$Purchase))
OJ.data=data.frame(OJ, as.factor(OJ$Purchase))
OJ.data=data.frame(OJ, OJ$Purchase= as.factor(OJ$Purchase))
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ, OJ$Purchase<- as.factor(OJ$Purchase))
OJ.data=data.frame(OJ)
nrow(OJ.data)
split<- sample.split(OJ.data$Purchase, SplitRatio = 0.7476636)
training_set<- subset(OJ.data, split==TRUE)
test_set<- subset(OJ.data, split==FALSE)
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
pred_test <- predict(svmfit, newdata = test_set[,-1])
confusion_matrix <- table(test_set[, 1], pred_test)
confusion_matrix
classification_error_test <- 1- sum(pred_test == test_set[,1])/length(pred_test)
classification_error_test
pred_train<-predict(svmfit, newdata = training_set[,-1])
classification_error_train <- 1- sum(pred_train == training_set[,1])/length(pred_train)
classification_error_train
opt_cost <- tune(svmfit, Purchase~., data = OJ.data, kernel = "linear",
ranges = list(cost = c(0.01:1000)))
opt_cost <- tune.svm(svmfit, Purchase~., data = OJ.data, kernel = "linear",
cost = seq(0.01,1000,by=0.01))
opt_cost <- tune.svm(svmfit, Purchase~., data = OJ.data, kernel = "linear",
cost = seq(0.01,1000,by=0.1))
model1<-glm(as.factor(Purchase)~., data=OJ.data)
model1<-glm(Purchase~., data=OJ.data)
model1<-lm(Purchase~., data=OJ.data)
model1<- lm(Purchase~., data=OJ.data)
opt_cost <- tune.svm(model1, data = OJ.data,
cost = seq(0.01,1000,by=0.1))
svm_tune<-tune(svm,train.x = training_set,train.y=test_set,kernel="linear",
ranges=list(cost=c(0.01:1000)))
train<-sample(nrow(OJ.data),800)
dim(OJ)
set.seed(888)
OJ.data=data.frame(OJ)
train<-sample(nrow(OJ.data),800)
training_set<- OJ.data[train,]
test_set<- OJ.data[-train,]
svmfit <- svm(Purchase ~ .,
data = training_set,
kernel = "linear",
cost = 0.01,
scale = FALSE)
summary(svmfit)
classification_error_test <- predict(svmfit,newdata=training_set)
classification_error_test <- predict(svmfit,newdata=training_set)
class.table(obs=training_set$Purchase,pred=classification_error_test)
??class.table
table(obs=training_set$Purchase,pred=classification_error_test)
classification_table(obs=training_set$Purchase,pred=classification_error_test)
??classification_table
class.table = function(obs,pred){
mytab = table(obs,pred)
correct = sum(diag(mytab))/sum(mytab)
for (i in 1:nrow(mytab)){
mytab[i,]=mytab[i,]/sum(mytab[i,])
}
print(round(mytab*100,1))
cat("overall:",round(100*correct,1),'\n')
}
classification_error_test <- predict(svmfit,newdata=training_set)
class.table(obs=training_set$Purchase,pred=classification_error_test)
classification_error_test <- predict(svmfit,newdata=test_set)
class.table(obs=test_set$Purchase,pred=classification_error_test)
classification_error_train <- predict(svmfit,newdata=training_set)
class.table(obs=training_set$Purchase,pred=classification_error_train)
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(0.01:1000)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(100:1000)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(888:999)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(666:999, by=11)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(888:999, by=11)))
888+11
888+11+11
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=list(888, 899, 910, 921, 932, 943, 954, 965, 976, 987, 998))
)
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(888, 899, 910, 921, 932, 943, 954, 965, 976, 987, 998)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="radial",
ranges=list(cost=c(888, 899, 910, 921, 932, 943, 954, 965, 976, 987, 998)))
optimal_cost <- svm_tune$best.model
optimal_cost
summary(svm_tune)
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(888, 899, 910, 921, 932, 943, 954, 965, 976, 987, 998)))
svm_tune<-tune(svm, Purchase~., data= training_set,kernel="linear",
ranges=list(cost=c(500, 510, 520, 530, 540, 550)))
summary(svm_tune)
best.train.pred <- predict(svm_tune$best.model,newdata=training_set)
class.table(obs=train_set$Purchase,pred=best.train.pred)
best.train.pred <- predict(svm_tune$best.model,newdata=training_set)
class.table(obs=training_set$Purchase,pred=best.train.pred)
best.test.pred<- predict(svm_tune$best.model,newdata=test_set)
class.table(obs=test_set$Purchase, pred=best.test.pred)
train=sample(1:nrow(Biden.data), p=0.75)
train=sample(1:nrow(Biden.data), 1355.25)
test= -train
train=sample(1:nrow(Biden.data), 1355.25)
Biden_training_set<- Biden.data[train,]
Biden_test_set<- Biden.data[-train,]
View(Biden.data)
boosted_tree_training <- function(lambda){
model <- gbm(biden ~ .,
data = nes[Biden_training_set,],
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=nes[Biden_training_set,], n.trees = 1000)
mse <- mean((nes[Biden_training_set,]$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boosted_tree_training <- function(lambda){
model <- gbm(biden ~ .,
data = Biden.data[Biden_training_set,],
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=nes[Biden_training_set,], n.trees = 1000)
mse <- mean((Biden.data[Biden_training_set,]$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boosted_tree_training <- function(lambda){
model <- gbm(biden ~ .,
data = Biden.data[Biden_training_set, ],
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=Biden.data[Biden_training_set, ], n.trees = 1000)
mse <- mean((Biden.data[Biden_training_set,]$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boost_training_list <- map(lambda, boosted_tree_training)
boosted_tree_training <- function(lambda){
model <- gbm(biden ~ .,
data = Biden_training_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=Biden_training_set, n.trees = 1000)
mse <- mean((Biden_training_set$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boost_training_mse <- as.data.frame(cbind(lambda, boost_training_list)) %>%
rename(mse = `boost_training_list`)
boosted_tree_testing <- function(lambda){
model <- gbm(biden ~ .,
data = Biden_test_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=Biden_test_set, n.trees = 1000)
mse <- mean((Biden_test_set$biden-preds)^2)
mse
}
boost_testing_list <- map_dbl(lambda, boosted_tree_testing)
boost_testing_mse <- as.data.frame(cbind(lambda, boost_testing_list)) %>%
rename(mse = `boost_testing_list`)
ggplot() +
geom_point(data = boost_training_mse, mapping = aes(lambda, mse), color = "blue") +
geom_line(data = boost_training_mse, mapping = aes(lambda, mse), color = "blue") +
geom_point(data = boost_testing_mse, mapping = aes(lambda, mse), color = "green") +
geom_line(data = boost_testing_mse, mapping = aes(lambda, mse), color = "green") +
labs(title = "Mean Squared Errors Across Shrinkage Values",
y = "MSE",
x = "Lambda",
subtitle = "Training (Blue), Testing (Green)")
ggplot() +
geom_point(data = boost_training_mse, mapping = aes(lambda, mse), color = "pink") +
geom_line(data = boost_training_mse, mapping = aes(lambda, mse), color = "pink") +
geom_point(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
geom_line(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
labs(title = "Mean Squared Errors Across Shrinkage Values",
y = "MSE",
x = "Lambda",
subtitle = "Training (Pink), Testing (Dark Cyan)")
ggplot() +
geom_point(data = boost_training_mse, mapping = aes(lambda, mse), color = "hotpink") +
geom_line(data = boost_training_mse, mapping = aes(lambda, mse), color = "hotpink") +
geom_point(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
geom_line(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
labs(title = "Mean Squared Errors Across Shrinkage Values",
y = "MSE",
x = "Lambda",
subtitle = "Training (Pink), Testing (Dark Cyan)")
lambda2<- 0.01
##Training
boosted_tree_training <- function(lambda2){
model <- gbm(biden ~ .,
data = Biden_training_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda2)
preds <- predict(model, newdata=Biden_training_set, n.trees = 1000)
mse <- mean((Biden_training_set$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda2, boosted_tree_training)
boost_training_mse <- as.data.frame(cbind(lambda2, boost_training_list)) %>%
rename(mse = `boost_training_list`)
##Testing
boosted_tree_testing <- function(lambda2){
model <- gbm(biden ~ .,
data = Biden_test_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda2)
preds <- predict(model, newdata=Biden_test_set, n.trees = 1000)
mse <- mean((Biden_test_set$biden-preds)^2)
mse
}
boost_testing_list <- map_dbl(lambda2, boosted_tree_testing)
boost_testing_mse <- as.data.frame(cbind(lambda2, boost_testing_list)) %>%
rename(mse = `boost_testing_list`)
##Training
boosted_tree_training <- function(lambda){
model <- gbm(biden ~ .,
data = Biden_training_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=Biden_training_set, n.trees = 1000)
mse <- mean((Biden_training_set$biden-preds)^2)
mse
}
boost_training_list <- map_dbl(lambda, boosted_tree_training)
boost_training_mse <- as.data.frame(cbind(lambda, boost_training_list)) %>%
rename(mse = `boost_training_list`)
##Testing
boosted_tree_testing <- function(lambda){
model <- gbm(biden ~ .,
data = Biden_test_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda)
preds <- predict(model, newdata=Biden_test_set, n.trees = 1000)
mse <- mean((Biden_test_set$biden-preds)^2)
mse
}
boost_testing_list <- map_dbl(lambda, boosted_tree_testing)
boost_testing_mse <- as.data.frame(cbind(lambda, boost_testing_list)) %>%
rename(mse = `boost_testing_list`)
##Plot
ggplot() +
geom_point(data = boost_training_mse, mapping = aes(lambda, mse), color = "hotpink") +
geom_line(data = boost_training_mse, mapping = aes(lambda, mse), color = "hotpink") +
geom_point(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
geom_line(data = boost_testing_mse, mapping = aes(lambda, mse), color = "darkcyan") +
labs(title = "Mean Squared Errors Across Shrinkage Values",
y = "MSE",
x = "Lambda",
subtitle = "Training (Pink), Testing (Dark Cyan)")
lambda2<- 0.01
##Training
boosted_tree_training2 <- function(lambda2){
model <- gbm(biden ~ .,
data = Biden_training_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda2)
preds <- predict(model, newdata=Biden_training_set, n.trees = 1000)
mse <- mean((Biden_training_set$biden-preds)^2)
mse
}
boost_training_list2 <- map_dbl(lambda2, boosted_tree_training2)
boost_training_mse2 <- as.data.frame(cbind(lambda2, boost_training_list2)) %>%
rename(mse = `boost_training_list2`)
##Testing
boosted_tree_testing2 <- function(lambda2){
model <- gbm(biden ~ .,
data = Biden_test_set,
distribution="gaussian",
n.trees=1000,
shrinkage = lambda2)
preds <- predict(model, newdata=Biden_test_set, n.trees = 1000)
mse <- mean((Biden_test_set$biden-preds)^2)
mse
}
boost_testing_list2 <- map_dbl(lambda2, boosted_tree_testing2)
boost_testing_mse2 <- as.data.frame(cbind(lambda2, boost_testing_list2)) %>%
rename(mse = `boost_testing_list2`)
boost_testing_mse2
boost_training_mse2
boost_training_mse
boost_testing_mse
bagging_training_set<- randomForest(biden~.,data=Biden_training_set,mtry = 10, importance = TRUE)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_training_set)
mean((predict_bag_train-Biden_training_set$biden))
bagging_training_set<- randomForest(biden~.,data=Biden_training_set, importance = TRUE)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_training_set)
mean((predict_bag_train-Biden_training_set$biden))
bagging_training_set<- randomForest(biden~.,data=Biden_training_set)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_training_set)
mean((predict_bag_train-Biden_training_set$biden)^2)
bagging_training_set<- randomForest(biden~.,data=Biden_training_set)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_training_set)
mse2<- mean((predict_bag_train-Biden_training_set$biden)^2)
mse2
bagging_training_set<- randomForest(biden~.,data=Biden_training_set)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_training_set)
mse2_train<- mean((predict_bag_train-Biden_training_set$biden)^2)
mse2_train
bagging_testing_set<- randomForest(biden~.,data=Biden_test_set)
predict_bag_test<- predict(bagging_testing_set,newdata=Biden_test_set)
mse2_test<- mean((predict_bag_test-Biden_test_set$biden)^2)
mse2_test
bagging_training_set<- randomForest(biden~.,data=Biden_training_set)
predict_bag_train<- predict(bagging_training_set,newdata=Biden_test_set)
mse2_train<- mean((predict_bag_train-Biden_test_set$biden)^2)
mse2_train
random_forest_train <- randomForest(biden ~ ., data = Biden.data, subset = Biden_training_set, mtry = 1, importance = TRUE)
random_forest_train <- randomForest(biden ~ ., data = Biden.data, subset = Biden_training_set)
random_forest_train <- randomForest(biden ~ ., data = Biden.data, subset = Biden_training_set, mtry=1)
random_forest_train <- randomForest(biden ~ ., data = Biden_training_set)
set.seed(888)
pred_randomforest_train <- predict(random_forest_train, newdata = Biden_test_set)
mean((pred_randomforest_train - Biden_test_set$biden)^2)
linear_model_train<- lm(biden~., data=Biden_training_set)
set.seed(888)
pred_lm<- predict(linear_model_train, newdata=Biden_test_set)
mse4<- mean((pred_lm- Biden_test_set$biden)^2)
mse4
class.table(obs=Biden_training_set$biden,pred=pred_lm)
class.table(obs=Biden_training_set$biden, pred=pred_lm)
